version: '3'
services:
  spark-master:
    image: bde2020/spark-master:3.1.1-hadoop3.2
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    volumes:
      - ./:/code
    #command: sh -c "cd /code ; ./setup.sh"
    #command: sh -c "cd /code ; spark-submit     --master spark://localhost:7077     --py-files packages.zip     --files configs/etl_config.json  jobs/domain/system/etl_job_base.py --job_name_arg hello "
  spark-worker-1:
    image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    volumes:
      - ./:/code
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"